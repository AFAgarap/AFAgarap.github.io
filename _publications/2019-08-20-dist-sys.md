---
title: "Training Deep Neural Networks for Image Classification in a Homogenous Distributed System"
collection: publications
permalink: /publication/2019-08-20-dist-sys
excerpt: "TLDR: Distributed training of feed-forward neural networks and ResNet50 using NVIDIA Tesla V100 GPU."
date: 2019-08-20
venue: "ResearchGate"
paperurl: "https://www.researchgate.net/publication/337731039_Training_Deep_Neural_Networks_for_Image_Classification_in_a_Homogenous_Distributed_System"
---

**Abstract:** In this article, we trained deep neural networks on both single node and dual node (distributed) manner. Each machine had an NVIDIA Tesla V100 GPU. First, we used a 2-layer feed-forward neural network on a perturbed MNIST dataset, and it took 2 minutes and 18 seconds to train on a single machine while it took 1 minute and 57 seconds to train on two machines. Second, we used a variant of the ResNet architecture with 56 layers on the CIFAR-10 dataset, and it took 62 minutes and 43 seconds to train on a single machine while it took 24 minutes and 38 seconds to train on two machines.


[Download paper here](https://www.researchgate.net/publication/337731039_Training_Deep_Neural_Networks_for_Image_Classification_in_a_Homogenous_Distributed_System)


Recommended citation: Agarap, A. F. Training Deep Neural Networks for Image Classification in a Homogenous Distributed System.
